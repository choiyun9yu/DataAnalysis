# Ada Boosting

## 1. What is AdaBoost?
- AdaBoost 는 Boosting 기법 중 하나로, 여러 약한 학습기를 결합하여 성능이 좋은 강한 학습기를 만드는 앙상블 기법이다.
- 특히 분류 문제에서 자주 사용되며, 약한 학습기는 보통 의사결정 트리와 같은 단순한 모델을 사용한다.
- AdaBoost 는 분류 문제를 해결하는 데 주로 사용되며, 각 학습기가 순차적으로 학습을 강화하여 성능을 향상시킨다.

### 1-1. Boosting 의 기본 개념
- Boosting 은 여러 개의 약한 학습기를 차례대로 학습시키고, 그 학습기들의 출력을 결합하여 최종 예측을 개선하는 방법이다.
- 각 약한 학습기는 이전 학습기들이 만든 오류를 보완하는 방식으로 학습해나간다.
  - 약한 학습기: 개별 성능은 낮지만, 오류율이 랜덤 추측보다는 나은 모델
  - 강한 학습기: 여러 약한 학습기를 결합하여 높은 정확도를 가지는 모델
- 핵심은 각 학습단계에서 잘못 예측되는 데이터 포인트에 더 큰 가중치를 부여하여, 다음 학습기가 이 오류를 고치도록 유도하는 것이다.

### 1-2. AdaBoost 작동 원리
#### 초기화
- 각 데이터 포인트에 대해 동일한 가중치를 부여하여 시작한다.
- 보통 각 데이터 포인트의 초기 가중치는 $w_1(i) = \frac{i}{N}$ 이다.
  여기서 N 은 전체 데이터 포인트의 수이다.

#### 반복 과정
