{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. sklearn map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn     \n",
    "# │     \n",
    "# ├── 01 preprocessing (전처리)     \n",
    "# │   │     \n",
    "# │   ├── 스케일러     \n",
    "# │   │   ├── MinMaxScaler     \n",
    "# │   │   ├── RobustScaler     \n",
    "# │   │   └── StandardScaler     \n",
    "# │   │     \n",
    "# │   └── 인코더     \n",
    "# │       ├── LabelEncoder     \n",
    "# │       └── OneHotEncoder     \n",
    "# │       \n",
    "# ├── 02 model_selection (모델링 전처리)     \n",
    "# │   │     \n",
    "# │   ├── 데이터셋 분리     \n",
    "# │   │   ├── KFold     \n",
    "# │   │   ├── StratifiedKFold     \n",
    "# │   │   └── train_test_split     \n",
    "# │   │     \n",
    "# │   └── 하이퍼파라미터 튜닝          \n",
    "# │       └── GridSearchCV     \n",
    "# │     \n",
    "# ├── 03 모델학습     \n",
    "# │   │     \n",
    "# │   ├── ensemble     \n",
    "# │   │   ├── AdaBoostClassifier     \n",
    "# │   │   ├── GradientBoostingClassifier     \n",
    "# │   │   ├── RandomForestClassifier     \n",
    "# │   │   └── RandomForestRegressor     \n",
    "# │   │     \n",
    "# │   ├── linear_model     \n",
    "# │   │   ├── LogisticRegression     \n",
    "# │   │   └── RidgeClassifier     \n",
    "# │   │     \n",
    "# │   ├── neighbors     \n",
    "# │   │   └── KNeighborsClassifier     \n",
    "# │   │     \n",
    "# │   ├── svm     \n",
    "# │   │   ├── SVC     \n",
    "# │   │   └── SVR     \n",
    "# │   │     \n",
    "# │   └── tree     \n",
    "# │       ├── DecisionTreeClassifier     \n",
    "# │       ├── DecisionTreeRegressor     \n",
    "# │       ├── ExtraTreeClassifier     \n",
    "# │       └── ExtraTreeRegressor     \n",
    "# │     \n",
    "# ├── 04 모델평가     \n",
    "# │   │     \n",
    "# │   ├── metrics     \n",
    "# │   │   ├── accuracy_score     \n",
    "# │   │   ├── classification_report     \n",
    "# │   │   ├── confusion_matrix     \n",
    "# │   │   ├── f1_score     \n",
    "# │   │   ├── log_loss          \n",
    "# │   │   ├── mean_absolute_error     \n",
    "# │   │   ├── mean_squared_error     \n",
    "# │   │   └── roc_auc_score     \n",
    "# │   │     \n",
    "# │   └── model (정의된 모델에서 추출)          \n",
    "# │       ├── predict     \n",
    "# │       └── predict_proba     \n",
    "# │     \n",
    "# └── 05 최종앙상블     \n",
    "#     │     \n",
    "#     └── ensemble     \n",
    "#         ├── StackingClassifier     \n",
    "#         ├── StackingRegressor     \n",
    "#         ├── VotingClassifier     \n",
    "#         └── VotingRegressor   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터 전처리"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['calibration', 'cluster', 'covariance', 'cross_decomposition', 'datasets', 'decomposition', 'dummy', 'ensemble', 'exceptions', 'experimental', 'externals', 'feature_extraction', 'feature_selection', 'gaussian_process', 'inspection', 'isotonic', 'kernel_approximation', 'kernel_ridge', 'linear_model', 'manifold', 'metrics', 'mixture', 'model_selection', 'multiclass', 'multioutput', 'naive_bayes', 'neighbors', 'neural_network', 'pipeline', 'preprocessing', 'random_projection', 'semi_supervised', 'svm', 'tree', 'discriminant_analysis', 'impute', 'compose', 'clone', 'get_config', 'set_config', 'config_context', 'show_versions']\n"
     ]
    }
   ],
   "source": [
    "# 가장 상위 모듈인 sklean의 바로 하위 항목을 확인하기 위헤서는 아래와 같이 입력\n",
    "import sklearn\n",
    "print(sklearn.__all__)\n",
    "\n",
    "# 중요하게 기억할 하위 모듈은 ensemble, linear_model, metrics, model_selection, preprocessing이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Binarizer', 'FunctionTransformer', 'KBinsDiscretizer', 'KernelCenterer', 'LabelBinarizer', 'LabelEncoder', 'MaxAbsScaler', 'MinMaxScaler', 'MultiLabelBinarizer', 'Normalizer', 'OneHotEncoder', 'OrdinalEncoder', 'PolynomialFeatures', 'PowerTransformer', 'QuantileTransformer', 'RobustScaler', 'SplineTransformer', 'StandardScaler', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_csr_polynomial_expansion', '_data', '_discretization', '_encoders', '_function_transformer', '_label', '_polynomial', 'add_dummy_feature', 'binarize', 'label_binarize', 'maxabs_scale', 'minmax_scale', 'normalize', 'power_transform', 'quantile_transform', 'robust_scale', 'scale']\n"
     ]
    }
   ],
   "source": [
    "# 2차 하위 모듈을 찾기 위해서는 dir 이용\n",
    "from sklearn import preprocessing\n",
    "print(dir(sklearn.preprocessing))\n",
    "\n",
    "# 최종 하위 모듈 찾았다면 from ~ import 구문을 이용해서 해당 모듈을 불러온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 스케일러\n",
    "sklearn.preprocessing의 스케일러는 StandardScaler, MinMaxScaler, RobustScaler 3가지  \n",
    "주로 사용하는 스케일러는 StandardScaler이고 동작방법은 모두 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환 전\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.2500</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.2833</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.9250</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fare   Age\n",
       "0   7.2500  22.0\n",
       "1  71.2833  38.0\n",
       "2   7.9250  26.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환 후\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.502445</td>\n",
       "      <td>-0.530377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.786845</td>\n",
       "      <td>0.571831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.488854</td>\n",
       "      <td>-0.254825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Fare       Age\n",
       "0 -0.502445 -0.530377\n",
       "1  0.786845  0.571831\n",
       "2 -0.488854 -0.254825"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://bit.ly/3BVZhFY')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# 스케일러의 주로 사용하는 내부함수는 fit, transform, fit_transform 3가지\n",
    "# 아래는 fit_transform 이용해서 값을 변화시키고, 원래 데이터 프레임의 칼럼에 입히는 작업\n",
    "print('변환 전')\n",
    "display(df[['Fare','Age']].head(3))\n",
    "df[['Fare','Age']] = sc.fit_transform(df[['Fare','Age']])\n",
    "print('변환 후')\n",
    "display(df[['Fare','Age']].head(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 라벨 인코더, 원핫 인코더\n",
    "데이터의 범주형 변수를 처리하기 위한 모듈은  \n",
    "sklearn.preprocessing의 LabelEncoder, OneHotEncoder 두가지이다.  \n",
    "라벨 인코딩은 컬럼수는 유지하며 내부의 범주형변수들을 특정 int값으로 매핑하는 것이고  \n",
    "원핫 인코딩은 유니크한 범주형 변수들만큼 컬럼을 만들고 일치하는 값일경우 0, 아닐 경우 1 사용  \n",
    "  \n",
    "! OneHotEncoder 대신에 판다스의 pd.get_dummies 함수가 더 편리함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변경 전\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      male\n",
       "1    female\n",
       "2    female\n",
       "Name: Sex, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label encodeing 사용 후\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    0\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "print('변경 전')\n",
    "display(df['Sex'][:3])\n",
    "\n",
    "lb = LabelEncoder()\n",
    "lb.fit(df['Sex'])\n",
    "\n",
    "print('label encodeing 사용 후')\n",
    "df['Sex'] = lb.transform(df['Sex'])\n",
    "display(df['Sex'][:3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) 학습데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train_test_split in module sklearn.model_selection._split:\n",
      "\n",
      "train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)\n",
      "    Split arrays or matrices into random train and test subsets.\n",
      "    \n",
      "    Quick utility that wraps input validation and\n",
      "    ``next(ShuffleSplit().split(X, y))`` and application to input data\n",
      "    into a single call for splitting (and optionally subsampling) data in a\n",
      "    oneliner.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    *arrays : sequence of indexables with same length / shape[0]\n",
      "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "        matrices or pandas dataframes.\n",
      "    \n",
      "    test_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "        of the dataset to include in the test split. If int, represents the\n",
      "        absolute number of test samples. If None, the value is set to the\n",
      "        complement of the train size. If ``train_size`` is also None, it will\n",
      "        be set to 0.25.\n",
      "    \n",
      "    train_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the\n",
      "        proportion of the dataset to include in the train split. If\n",
      "        int, represents the absolute number of train samples. If None,\n",
      "        the value is automatically set to the complement of the test size.\n",
      "    \n",
      "    random_state : int, RandomState instance or None, default=None\n",
      "        Controls the shuffling applied to the data before applying the split.\n",
      "        Pass an int for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "    \n",
      "    shuffle : bool, default=True\n",
      "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "        then stratify must be None.\n",
      "    \n",
      "    stratify : array-like, default=None\n",
      "        If not None, data is split in a stratified fashion, using this as\n",
      "        the class labels.\n",
      "        Read more in the :ref:`User Guide <stratification>`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    splitting : list, length=2 * len(arrays)\n",
      "        List containing train-test split of inputs.\n",
      "    \n",
      "        .. versionadded:: 0.16\n",
      "            If the input is sparse, the output will be a\n",
      "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "            input type.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.model_selection import train_test_split\n",
      "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "    >>> X\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5],\n",
      "           [6, 7],\n",
      "           [8, 9]])\n",
      "    >>> list(y)\n",
      "    [0, 1, 2, 3, 4]\n",
      "    \n",
      "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "    ...     X, y, test_size=0.33, random_state=42)\n",
      "    ...\n",
      "    >>> X_train\n",
      "    array([[4, 5],\n",
      "           [0, 1],\n",
      "           [6, 7]])\n",
      "    >>> y_train\n",
      "    [2, 0, 3]\n",
      "    >>> X_test\n",
      "    array([[2, 3],\n",
      "           [8, 9]])\n",
      "    >>> y_test\n",
      "    [1, 4]\n",
      "    \n",
      "    >>> train_test_split(y, shuffle=False)\n",
      "    [[0, 1, 2], [3, 4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>125</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   60    1   0       140   293    0        0      170      0      1.2      1   \n",
       "1   51    0   2       120   295    0        0      157      0      0.6      2   \n",
       "2   51    1   3       125   213    0        0      125      1      1.4      2   \n",
       "3   59    1   2       150   212    1        1      157      0      1.6      2   \n",
       "4   60    1   0       125   258    0        0      141      1      2.8      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     2       1  \n",
       "2   1     2       1  \n",
       "3   0     2       1  \n",
       "4   1     3       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://bit.ly/3EMMasy')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas의 drop 함수를 이용하여 종속변수를 날리고 독립변수만 모아 x 변수로 지정\n",
    "y = df['target']\n",
    "X = df.drop(columns='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=777,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape (242, 14)\n",
      "X_train shape (162, 13)\n",
      "X_test shape (80, 13)\n",
      "y_train shape (162,)\n",
      "y_test shape (80,)\n"
     ]
    }
   ],
   "source": [
    "print('df shape',df.shape)\n",
    "print('X_train shape',X_train.shape)\n",
    "print('X_test shape',X_test.shape)\n",
    "print('y_train shape',y_train.shape)\n",
    "print('y_test shape',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본데이터의 target value 값 개수\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    132\n",
       "0    110\n",
       "Name: target, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터 target value 값 개수\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    88\n",
       "0    74\n",
       "Name: target, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#층화 추출이 잘 되었는지 확인\n",
    "print('원본데이터의 target value 값 개수')\n",
    "display(df.target.value_counts())\n",
    "print('학습데이터 target value 값 개수')\n",
    "display(y_train.value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 모델링\n",
    "- 모델 import \n",
    "- 모델 변수 선언\n",
    "- fit(학습)\n",
    "- predict or predict_proba(분류문제의 auc계산을 위한 예측확률값)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주로 사용하는 모델 import 과정\n",
    "from sklearn.ensemble import RandomForestClassifier #랜덤포레스트분류\n",
    "from sklearn.ensemble import RandomForestRegressor  #랜덤포레스트회귀\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression #로지스틱회귀\n",
    "from sklearn.svm import SVC #서포트 벡터머신 분류\n",
    "from sklearn.svm import SVR #서포트 벡터머신 회귀\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier #의사결정나무 분류\n",
    "from sklearn.tree import DecisionTreeRegressor  #의사결정나무 회귀\n",
    "\n",
    "# 모든 모듈을 외우기는 힘들다 \n",
    "# 위에서 제시한 sklearn 모듈 찾기 방식으로 필요한 모델들을 찾아가면된다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 렌덤 포레스트 모델링 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_value [1 0 1] \n",
      "\n",
      "predict_proba_value\n",
      " [[0.48 0.52]\n",
      " [0.98 0.02]\n",
      " [0.17 0.83]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델 import\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 모델 변수선언\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# fit\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "# predict\n",
    "predict_value = rf.predict(X_test)\n",
    "\n",
    "# predict_proba\n",
    "predict_proba_value = rf.predict_proba(X_test)\n",
    "\n",
    "# predict와 predict_proba의 3개값 확인\n",
    "print('predict_value',predict_value[:3],'\\n')\n",
    "print('predict_proba_value\\n',predict_proba_value[:3],'\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델 평가\n",
    "sklearn.metric에서 문제에서 제시하는 평가방식을 import 해서 사용  \n",
    "평가방식의 y_test, predict형식에 대해서는 일부 차이가 있을 수 있음  \n",
    "지표마다 help함수를 이용해서 parameter의 형식을 확인하고 코딩해야함  \n",
    "  \n",
    "주로 쓰는 평가방식 \n",
    "- accuracy_score(정확도)\n",
    "- f1_score (f1,score)\n",
    "- mean_absolute_error (mae)\n",
    "- mean_squared_error (mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9305555555555555"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "# help(roc_auc_score)\n",
    "roc_auc_score(y_test,predict_proba_value[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
