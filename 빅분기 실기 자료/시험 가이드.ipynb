{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유형1 : 데이터 전처리 작업 3문제 * 10 [30점]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# csv 파일 불러오기 \n",
    "df = pd.read_csv('파일경로.csv')\n",
    "## 불러오면서 인덱스 컬럼 설정\n",
    "df_csv1 = pd.read_csv('파일경로.csv', index_col='인덱스로 삼을 칼럼명')\n",
    "## 불러오면서 구분자 지정\n",
    "df_csv2 = pd.read_csv('파일경로.csv', sep='\\t')\n",
    "## 불러올 때 언어 설정\n",
    "df_csv3 = pd.read_csv('파일경로.csv', encoding='euc-kr')  # 한글지원 : euc-kr, cp949\n",
    "\n",
    "# excel 파일 불러오기 (엑셀은 엔진 설정해주기!!)\n",
    "df_excel = pd.read_excel('파일경로.xlsx', engine='openpyxl')\n",
    "\n",
    "# csv 파일 저장하기\n",
    "df.to_csv('경로.csv', index=False)\n",
    "# excel 파일 저장하기\n",
    "df.to_excel('경로.xlsx', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 구조 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음부터 n개 행의 데이터 확인\n",
    "df.head()\n",
    "# 끝부터 n개 행의 데이터 확인\n",
    "df.tail()\n",
    "\n",
    "# 데이터프레임 row개수, colum개수, Not null,dtype 등 정보 확인\n",
    "df.info()\n",
    "# 데이터프레임 통계 정보 확인\n",
    "df.describe()\n",
    "\n",
    "# 데이터프레임의 행, 열의 수를 (행, 열)형태의 튜블로 반환\n",
    "df.shape\n",
    "# 데이터프레임의 (행 x 열)의 전체 데이터 수를 반환\n",
    "df.size\n",
    "# 데이터프레임 데이터 타입 확인\n",
    "df.dtypes\n",
    "\n",
    "# 시리즈\n",
    "sri = df['특정 컬럼']\n",
    "# 시리즈 데이터 타입 확인\n",
    "sri.dtypes\n",
    "\n",
    "#데이터프레임의 인덱스 확인 (보통 0으로 시작해서 몇으로 끝나고 스텝이 몇인지 등을 보여줌)\n",
    "df.index\n",
    "# 데이터프레임의 컬럼 확인\n",
    "df.columns          # 타입 index\n",
    "df.columns.values   # 타입 array\n",
    "# 데이터프레임의 구성요소 2차원으로 보기\n",
    "df.values           # 타입 array\n",
    "\n",
    "# 시리즈의 구성요소\n",
    "sri.values          # 타입 array 해당 시리즈 값 배열로 쭉 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시리즈 중 컬럼에 존재하는 값 종류만 확인\n",
    "sri.unique()\n",
    "# 시리즈 중 컬럼에 존재하는 값 종류의 개수만 확인\n",
    "sri.nunique()\n",
    "# 시리즈 중 컬럼에 대해 값 별 개수 확인\n",
    "sri.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame의 index, columns 및 Series의 index 는 대입연산을 사용하여 변경 가능 다만, 개수가 동일해야 함  \n",
    "  \n",
    "value는 인덱스를 이용해서 변경 가능  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼 개수 확인 -> 컬럼 이름 리스트를 대입 연산자로 넣기(단, 개수 동일하게)\n",
    "df.columns = ['컬럼1', '컬럼2', '컬럼3']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터 타입 변경\n",
    "데이터 타입 변경 전 데이터 조작이 필요할 수 있음 (예) 불필요 문자/콤마/공백 제거, 단위 변환 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시리즈 데이터 타입 변경 ('int', 'int32', 'int64', 'float', 'str', 'category' 등)\n",
    "## 넘파이 타입으로 하려면 넘파이 임포트 하여야함 (np.int16, np.float32, np.datetime64 등)\n",
    "sri.astype('타입')\n",
    "\n",
    "# 원하는 자료형으로 바꾸지 못하는 장애요소 제거하고 변환\n",
    "## replace 사용 시 regex=True 옵션을 사용하면 일부 내용만 변경대상으로 지정할 수 있음\n",
    "## 여기서 regex는 '정규표현식'을 의미\n",
    "sri.replace('변경전', '변경후', regex=True)\n",
    "# 변경할 내용이 두가지 이상일 때 list나 dic을 사용하여 변환\n",
    "list1 = ['변경전1', '변경전2']\n",
    "list2 = ['변경후1', '변경후2']\n",
    "sri.replace(list1, list2, regex=True)\n",
    "dic = {'변경전1':'변경후1', '변경전2':'변경후2'}\n",
    "sri.replace(dic, regex=True).astype('int64')\n",
    "\n",
    "## ,콤마는 메타 문자이므로 제거하고자 하는 경우 \\, 처럼 역슬레시 사용\n",
    "## 메타문자 종류 , . + ? * ^ $ 등\n",
    "sri.replace(['\\메타문자', '변견전2'], '', regex=True)  # 변경후 모습이 같다면 하나만 적어도 됨\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series는 Accessor라는 것을 가지고 있다. Accessor를 사용하기 위해서라도 데이터 타입 변경 필요\n",
    "- dt : Datetime, Timedelta, Period\n",
    "- str : String\n",
    "- cat : Categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accessor 사용 .str accessor 사용하면 각 행에 문자열 처럼 접근 \n",
    "sri.str[1:-1].astype('category')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적인 np.datetime64 나 category 타입 변경은 astype으로 변경 가능, 특수한 경우는 아래 방법 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime\n",
    "import numpy as np\n",
    "sri.astype(np.datetime64)  # 일/월/년 순으로 보기도 함 이런 경우 to_datatime을 사용\n",
    "# 내가 원하는 방식으로 날짜를 읽어오고 싶을 때\n",
    "## %Y: 4글자 년도, %y : 2글자 년도, %m : 2글자 월, %d : 2글자 일\n",
    "pd.to_datetime(sri, format='%y-%m-%d')\n",
    "\n",
    "# category\n",
    "sri.astype('category')  # 이렇게 변환한 자료에 sort_values 적용하면 가나다 순 정렬됨 \n",
    "# 카테고리 순서를 직접 지정하고 싶을 때\n",
    "temp = pd.Categorical(sri, categories=[\"범주1\", \"범주2\"], ordered=True)  # 이건 지금 시리즈는 아님\n",
    "sri = temp  # 이건 시리즈\n",
    "sri.sort_values() # 원하는 순서대로 정렬 할 수 있음"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 데이터 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort_index() : 인덱스 정렬\n",
    "\n",
    "# sort_values() : 밸류 정렬, 디폴트(내림차순)\n",
    "df.sort_values('정렬기준칼럼')\n",
    "# 오름차순인 경우\n",
    "df.sort_values('정렬기준칼럼', ascending=True)\n",
    "# 정렬 기준이 여러개인 경우\n",
    "df.sort_values(['1차기준', '2차기준'])  \n",
    "# 정렬 기준이 여러개, 내림차순 오름차순도 여러개인 경우\n",
    "df.sort_values(['1차기준', '2차기준'], ascending=[True, False])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 데이터 통계 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 데이터 정제하기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 결측치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 이상치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 파생 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유형2 : 데이터 전처리 및 모델링 1문제(40*1)\n",
    "    1. 데이터 불러오기 : pd.read_csv('.csv', index_col=0)\n",
    "    2. 데이터 정제하기\n",
    "        1) 결측치 제거 or 대체\n",
    "        2) 이상치 제거 or 대체\n",
    "    3. 데이터 변환하기\n",
    "        1) 불리언 인덱싱\n",
    "        2) np.where(조건식)\n",
    "    4. 범주형 데이터 라벨링\n",
    "        1) LabelEncoding\n",
    "        2) one-hot-encoding(getdummys()?)\n",
    "    5. 뉴메리컬 데이터 스케일링\n",
    "        1) StandardScaler\n",
    "        2) MinMaxScaler\n",
    "    6. 모델링\n",
    "        1) 지도학습 분류 : RandomforestClassifier\n",
    "        2) 지도학습 회귀 : RandomforestRegressor\n",
    "        3) 비지도학습 군집화\n",
    "    7. 모델 적용\n",
    "        1) train_test_split(층화 추출 옵션stratify = y)\n",
    "        2) new - fit - predict\n",
    "    8. 모델 성능 확인 : 문제에서 요구하는 평가지표에 맞게 수행\n",
    "        1) 지도 학습\n",
    "            - 정확도(accuracy)\n",
    "            - 정밀도(precision)\n",
    "            - 재현율(recall)\n",
    "            - 특이도(Specificity)\n",
    "            - f1_score : \n",
    "            - ROC(Receiver Operating Characteristic) 곡선: \n",
    "            - AUC(Are Under Curve) : \n",
    "        2) 회귀 학습\n",
    "            - SSE(Sum Squared Error) : \n",
    "            - MSE(Mean Squared Error) : \n",
    "            - RMSE(Root Mean Squared Error) :\n",
    "            - MAE(Mean Absolute Error) : \n",
    "            - 결정계수(R2) :\n",
    "            - Adjusted R2 : \n",
    "            - MSPE(Mean Squared Percentage Error) : \n",
    "            - MAPE(Mean Absolute Percentage Error) :\n",
    "            - RMSLE(Root Mean Squared Logarithmic Error) : \n",
    "            - AIC(Akaike Information Criterion) : \n",
    "            - BIC(Bayes Information Criteria) : \n",
    "        3) 비지도 학습\n",
    "            - 실루엣 계수(Silhouette) : \n",
    "            - Dunn lndex : \n",
    "            - 군집 분석\n",
    "            - 연관 분석\n",
    "    9. 예측 값 저장 \n",
    "        submission.columns([''])\n",
    "        to_csv('.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "유형3 : 데이터 검증 2문제(15*2)\n",
    "    1. 데이터 불러오기 : pd.read_csv('.csv', index_col=0)\n",
    "    2. 데이터 파악하기 : data.describe()\n",
    "    3. 데이터 검증하기\n",
    "    귀무가설(h0) 대신 대립가설(h1)을 선택할 시 오류를 범할 최대의 확률 값으로 0.05 이하이면 유의하여 대립가설 채택, 일반적으로 채택/기각은 귀무가설 기준\n",
    "        01) t-검정\n",
    "            (1)\n",
    "            (2)\n",
    "            (3)\n",
    "        02) 정규성 검정\n",
    "            (1)\n",
    "            (2)\n",
    "        03) One-way ANOVA\n",
    "        04) Two-way ANOVA\n",
    "        05) 카이제곱 검정\n",
    "            (1) 독립성 검정\n",
    "            (2) 동질성 검정\n",
    "            (3) 적합성 검정\n",
    "        06) 순위 검정\n",
    "            (1) 윌콕슨 순위합 검정\n",
    "            (2) 크루스칼 - 왈리스 검정\n",
    "        07) 부호검정\n",
    "            (1) 부호검정\n",
    "            (2) 맥네마 검정\n",
    "        08) 다변량 추론\n",
    "            (1) 다중 회귀 분석\n",
    "\n",
    "    4. 결과값 입력하기\n",
    "\n",
    "\n",
    "\n",
    "t-검정 이해하기\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
